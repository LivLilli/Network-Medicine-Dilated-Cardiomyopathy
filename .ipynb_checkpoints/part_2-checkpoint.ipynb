{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import markov_clustering as mc\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import hypergeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "union_df = pd.read_csv('results/union.csv', index_col=0)\n",
    "intersection_df = pd.read_csv('results/intersection.csv', index_col=0)\n",
    "sgi_df = pd.read_csv('results/sgi.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2_1_a(df, type_net):\n",
    "    # undirected graph object\n",
    "    graph = nx.from_pandas_edgelist(df, source = 'interactor A gene symbol', target='interactor B gene symbol')\n",
    "    # check number of nodes\n",
    "    if graph.number_of_nodes() >20:\n",
    "        n_nodes = graph.number_of_nodes()\n",
    "        # not consider the duplicates (union can have same edges with different sources: they will be considered just one time)\n",
    "        n_edges = graph.number_of_edges()\n",
    "        # number of connected components\n",
    "        conn_components = nx.number_connected_components(graph)\n",
    "        # number of isolates\n",
    "        n_isolates = nx.number_of_isolates(graph)\n",
    "        # average degree\n",
    "        avg_degree = n_edges/n_nodes\n",
    "        # avg clustering coefficient\n",
    "        avg_cluster_coeff = nx.average_clustering(graph)\n",
    "        \n",
    "        print('%s'%type_net,'network has: \\n')\n",
    "        print(n_nodes, 'nodes')\n",
    "        print(n_edges, 'edges')\n",
    "        print(conn_components,'connected components')\n",
    "        print(n_isolates, 'isolated nodes')\n",
    "        print('average degree = ', avg_degree)\n",
    "        print('average clustering coefficient = ', avg_cluster_coeff)\n",
    "        \n",
    "        # if graph is connected\n",
    "        if conn_components ==1:\n",
    "            \n",
    "            # average shprtest path length\n",
    "            avg_path = nx.average_shortest_path_length(graph)\n",
    "            # diameter \n",
    "            diameter = nx.diameter(graph)\n",
    "            # radius \n",
    "            radius = nx.radius(graph)\n",
    "        \n",
    "            print('shortest path length = ', avg_path)\n",
    "            print('diameter = ', diameter)\n",
    "            print('radius = ', radius)\n",
    "            \n",
    "        # if graph not connected  \n",
    "        else:\n",
    "            ll=[]\n",
    "            #for each connected component computes the properties\n",
    "            c = 1\n",
    "            for g in nx.connected_component_subgraphs(graph): \n",
    "            \n",
    "                print('Connected Component',c)\n",
    "                print('Number of nodes: ', nx.number_of_nodes(g))\n",
    "                print('Number of edges: ', nx.number_of_edges(g))\n",
    "                print('average Shortest Path: ', nx.average_shortest_path_length(g))\n",
    "                print('diameter', nx.diameter(g))\n",
    "                print('radius', nx.radius(g))\n",
    "                c +=1\n",
    "    else:\n",
    "        print('%s'%type_net,'network do not have a number of edges bigger than 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection network has: \n",
      "\n",
      "57 nodes\n",
      "89 edges\n",
      "10 connected components\n",
      "0 isolated nodes\n",
      "average degree =  1.5614035087719298\n",
      "average clustering coefficient =  0.09359509885825675\n",
      "Connected Component 1\n",
      "Number of nodes:  44\n",
      "Number of edges:  77\n",
      "average Shortest Path:  3.6659619450317127\n",
      "diameter 9\n",
      "radius 5\n",
      "Connected Component 2\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 3\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 4\n",
      "Number of nodes:  2\n",
      "Number of edges:  2\n",
      "average Shortest Path:  1.0\n",
      "diameter 1\n",
      "radius 1\n",
      "Connected Component 5\n",
      "Number of nodes:  3\n",
      "Number of edges:  3\n",
      "average Shortest Path:  1.3333333333333333\n",
      "diameter 2\n",
      "radius 1\n",
      "Connected Component 6\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 7\n",
      "Number of nodes:  2\n",
      "Number of edges:  1\n",
      "average Shortest Path:  1.0\n",
      "diameter 1\n",
      "radius 1\n",
      "Connected Component 8\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 9\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 10\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n"
     ]
    }
   ],
   "source": [
    "task_2_1_a(intersection_df, 'Intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union network has: \n",
      "\n",
      "5513 nodes\n",
      "10329 edges\n",
      "2 connected components\n",
      "0 isolated nodes\n",
      "average degree =  1.8735715581353165\n",
      "average clustering coefficient =  0.07321978067098309\n",
      "Connected Component 1\n",
      "Number of nodes:  5509\n",
      "Number of edges:  10326\n",
      "average Shortest Path:  3.4924265343579193\n",
      "diameter 7\n",
      "radius 4\n",
      "Connected Component 2\n",
      "Number of nodes:  4\n",
      "Number of edges:  3\n",
      "average Shortest Path:  1.5\n",
      "diameter 2\n",
      "radius 1\n"
     ]
    }
   ],
   "source": [
    "task_2_1_a(union_df, 'Union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGI network has: \n",
      "\n",
      "74 nodes\n",
      "176 edges\n",
      "13 connected components\n",
      "0 isolated nodes\n",
      "average degree =  2.3783783783783785\n",
      "average clustering coefficient =  0.15667418167418168\n",
      "Connected Component 1\n",
      "Number of nodes:  61\n",
      "Number of edges:  164\n",
      "average Shortest Path:  3.23879781420765\n",
      "diameter 7\n",
      "radius 4\n",
      "Connected Component 2\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 3\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 4\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 5\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 6\n",
      "Number of nodes:  2\n",
      "Number of edges:  1\n",
      "average Shortest Path:  1.0\n",
      "diameter 1\n",
      "radius 1\n",
      "Connected Component 7\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 8\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 9\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 10\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 11\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 12\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n",
      "Connected Component 13\n",
      "Number of nodes:  1\n",
      "Number of edges:  1\n",
      "average Shortest Path:  0\n",
      "diameter 0\n",
      "radius 0\n"
     ]
    }
   ],
   "source": [
    "task_2_1_a(sgi_df, 'SGI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class LCC\n",
    "\n",
    "Save to csv the adjacency matrix in order to use it on R.\n",
    "\n",
    "Compute global and local measures of the largest connected component \n",
    "    of the graph corresponding to the given df.\n",
    "'''\n",
    "\n",
    "class LCC(object):\n",
    "    def __init__(self, dataframe, data_type):\n",
    "        '''\n",
    "        - dataframe: dataset corresponding to the union or the intersection\n",
    "        \n",
    "        - data_type: string to indicate type of df ('union' or 'intersection')\n",
    "        '''\n",
    "        \n",
    "        self.df = dataframe\n",
    "        self.data_type = data_type\n",
    "    \n",
    "    def lcc_graph(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        \n",
    "            - largest connected component graph\n",
    "        '''\n",
    "        # create graph from df\n",
    "        graph = nx.from_pandas_edgelist(self.df, source = 'interactor A gene symbol', target='interactor B gene symbol')\n",
    "        # return set of nodes of the largest connected component\n",
    "        lcc_set = max(nx.connected_components(graph), key=len)\n",
    "        # lcc subgraph\n",
    "        lcc_graph = graph.subgraph(lcc_set)\n",
    "        return lcc_graph\n",
    "    \n",
    "    def lcc_a_matrix_to_csv(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        \n",
    "            - file .csv with the adjacency matrix of the graph corresponding \n",
    "                to the df given in input to the class. \n",
    "        \n",
    "        It is necessary saving the matrix on an external file in order to use it for more \n",
    "            computations in R, where specific functions are faster.\n",
    "        '''\n",
    "    \n",
    "        # lcc subgraph\n",
    "        lcc_graph = self.lcc_graph()\n",
    "        # numpy adj matrix\n",
    "        a= nx.to_numpy_matrix(lcc_graph)\n",
    "        try:\n",
    "            os.remove('data/%s'%self.data_type +'_lcc_matrix.csv')\n",
    "        except:\n",
    "            pass\n",
    "        # save to csv\n",
    "        #np.savetxt('data/%s'%data_type+'_lcc_matrix.csv', a, delimiter=\",\", header='')\n",
    "        pd.DataFrame(a).to_csv('data/%s'%self.data_type +'_lcc_matrix.csv')\n",
    "\n",
    "    def task_2_1_b_global(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        \n",
    "            - df: dataframe of global measures for the graph which corresponds to the \n",
    "                input dataframe (union or inters).\n",
    "            \n",
    "            - nodes: list of nodes names of the graph.\n",
    "        '''\n",
    "        # lcc subgraph\n",
    "        lcc_graph = self.lcc_graph()\n",
    "        # number of nodes\n",
    "        n_nodes = lcc_graph.number_of_nodes()\n",
    "        # number of edges\n",
    "        # not consider the duplicates (union can have same edges with different sources: they will be considered just one time)\n",
    "        n_edges = lcc_graph.number_of_edges()\n",
    "        # average degree\n",
    "        avg_degree = n_edges/n_nodes\n",
    "        # avg clustering coefficient\n",
    "        avg_cluster_coeff = nx.average_clustering(lcc_graph)\n",
    "        # create df\n",
    "        df = pd.DataFrame([n_nodes, n_edges, avg_degree, avg_cluster_coeff])\n",
    "        df.rename({0:'Nodes', 1:'Edges', 2:'Avg Degree', 3:'Avg Clustering Coeff'}, inplace = True)\n",
    "        # lcc nodes\n",
    "        nodes = list(lcc_graph.nodes())\n",
    "        return df, nodes\n",
    "\n",
    "    def merge_global_measures(self):\n",
    "        '''\n",
    "        Return:\n",
    "        \n",
    "            - dataframe containing the global measures of the graph computed on Python and R.\n",
    "                In particular there are: number of edges and nodes, avg degree, avg clustering coefficient, \n",
    "                    avg. path length, diameter and radius. \n",
    "        \n",
    "        '''\n",
    "        # compute the above function to obtain global measures\n",
    "        lcc_global1, lcc_nodes  = self.task_2_1_b_global()\n",
    "        # upload the df containg avg shortest path, diameter and radius\n",
    "        # it was computed on R because of the better computational time of the functions\n",
    "        lcc_global2 = pd.read_csv('data/%s'%self.data_type+'_lcc_global_results.csv')\n",
    "        # concatenate the 2 dataframe in one\n",
    "        lcc_global = pd.concat([lcc_global1.T, lcc_global2], axis = 1).drop(['Unnamed: 0'], axis=1)\n",
    "        lcc_global = lcc_global.rename({0:'lcc_%s'%self.data_type}) \n",
    "        \n",
    "        return lcc_global\n",
    "    \n",
    "    def save_local_results(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        \n",
    "            - file .csv with the local measures related to the graph of the input df (union or intersection)\n",
    "        '''\n",
    "        # lcc nodes names\n",
    "        _,lcc_nodes = self.task_2_1_b_global()\n",
    "        # load local dfs computed on R because of the better computational time\n",
    "        lcc_local = pd.read_csv('data/%s'%self.data_type +'_lcc_local_results.csv').drop('Unnamed: 0', axis=1)\n",
    "        # rename rows with gene names\n",
    "        lcc_local = lcc_local.rename(dict(zip([x for x in range(len(lcc_local))],lcc_nodes)))\n",
    "        # save local df results\n",
    "        try:\n",
    "            os.remove('results/%s'%self.data_type +'_lcc_local.csv')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        lcc_local.to_csv('results/%s'%self.data_type +'_lcc_local.csv')\n",
    "        \n",
    "    def mcl_algo(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            \n",
    "            - Scipy sparse adjacency matrix.\n",
    "            - List of clusters: each cluster is a sublist containing the nodes which belongs to it.\n",
    "            \n",
    "        '''\n",
    "        graph = self.lcc_graph()\n",
    "        adj_matrix = nx.to_scipy_sparse_matrix(graph)\n",
    "        ### !!! attention: it works only with scipy version 1.2.0 !!!\n",
    "        result = mc.run_mcl(adj_matrix)           # run MCL with default parameters\n",
    "        clusters = mc.get_clusters(result)  # get clusters\n",
    "        return adj_matrix,clusters\n",
    "    \n",
    "    def mcl_plot():\n",
    "        adj_matrix, clusters = self.mcl_algo()\n",
    "        mc.draw_graph(adj_matrix, clusters, node_size=50, with_labels=False, edge_color=\"silver\")\n",
    "        \n",
    "        \n",
    "    def hypergeometric_test(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        \n",
    "            - Dictionary where for each cluster id gives the corresponding p-value.\n",
    "        '''\n",
    "        _ , lcc_clusters = self.mcl_algo()\n",
    "        # list of lcc nodes names\n",
    "        _, lcc_nodes = self.task_2_1_b_global()\n",
    "        # list of seeds genes\n",
    "        seed_genes = list(pd.read_csv('seed_genes.txt', header=None)[0])\n",
    "        # seeds in lcc\n",
    "        seeds_lcc = [x for x in seed_genes if x in lcc_nodes]\n",
    "        # population M = number of genes in lcc\n",
    "        pop = len(lcc_nodes)\n",
    "        #initialize p-values dictionary\n",
    "        p_values = {}\n",
    "        for cluster in lcc_clusters:\n",
    "            # n nodes in cluster\n",
    "            cluster_dimension = len(cluster)\n",
    "            # check number of nodes\n",
    "            if cluster_dimension >= 10:\n",
    "                # list of seed genes in cluster\n",
    "                seeds_in_cluster = [x for x in cluster if lcc_nodes[x] in seeds_lcc]\n",
    "                # number of seeds in cluster\n",
    "                n_seeds_in_cluster = len(seeds_in_cluster)\n",
    "                M,n,N,x =  pop, cluster_dimension,len(seeds_lcc),n_seeds_in_cluster\n",
    "                pval = hypergeom.sf(x-1, M, n, N)\n",
    "                p_values[c] = pval\n",
    "        # putatitive diseases modules dictionary\n",
    "        pdm_dic = {}\n",
    "        for i in p_values.keys():\n",
    "\n",
    "            if p_values[i] < 0.05:\n",
    "                pdm_dic[i] = p_values[i]\n",
    "\n",
    "        return pdm_dic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the class for the 2 dataframes\n",
    "LCC_union = LCC(union_df, 'union')\n",
    "LCC_inters = LCC(intersection_df, 'intersection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save adjacency matrix for the 2 graphs in order to use it on R\n",
    "LCC_union.lcc_a_matrix_to_csv()\n",
    "LCC_inters.lcc_a_matrix_to_csv()\n",
    "\n",
    "### TASK 2.1 B - GLOBAL\n",
    "# union global measures df \n",
    "lcc_union_global = LCC_union.merge_global_measures()\n",
    "# intersection global measures df \n",
    "lcc_inters_global = LCC_inters.merge_global_measures()\n",
    "# concatenate the 2 final dataframes\n",
    "lcc_global = pd.concat([lcc_union_global, lcc_inters_global], axis = 0)\n",
    "# save resulting df on csv\n",
    "# remove if already existing adn then create the new one\n",
    "try:\n",
    "    os.remove('results/lcc_global.csv')\n",
    "except: \n",
    "    pass\n",
    "lcc_global.to_csv('results/lcc_global.csv')\n",
    "\n",
    "\n",
    "### TASK 2.1 B - LOCAL\n",
    "\n",
    "# save lcc union local results\n",
    "LCC_union.save_local_results()\n",
    "# save lcc intersection local results\n",
    "LCC_inters.save_local_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 2.2\n",
    "pdm_lcc_union = LCC_union.hypergeometric_test()\n",
    "pdm_lcc_inters = LCC_inters.hypergeometric_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdm_lcc_union\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdm_lcc_inters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
